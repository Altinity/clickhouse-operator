# altinity-clickhouse-operator

![Version: 0.22.0](https://img.shields.io/badge/Version-0.22.0-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 0.22.0](https://img.shields.io/badge/AppVersion-0.22.0-informational?style=flat-square)

Helm chart to deploy [altinity-clickhouse-operator](https://github.com/Altinity/clickhouse-operator).

The ClickHouse Operator creates, configures and manages ClickHouse clusters running on Kubernetes.

For upgrade please install CRDs separately:
```bash
  kubectl apply -f https://github.com/Altinity/clickhouse-operator/raw/master/deploy/helm/crds/CustomResourceDefinition-clickhouseinstallations.clickhouse.altinity.com.yaml
  kubectl apply -f https://github.com/Altinity/clickhouse-operator/raw/master/deploy/helm/crds/CustomResourceDefinition-clickhouseinstallationtemplates.clickhouse.altinity.com.yaml
  kubectl apply -f https://github.com/Altinity/clickhouse-operator/raw/master/deploy/helm/crds/CustomResourceDefinition-clickhouseoperatorconfigurations.clickhouse.altinity.com.yaml
```

**Homepage:** <https://github.com/Altinity/clickhouse-operator>

## Maintainers

| Name | Email | Url |
| ---- | ------ | --- |
| altinity | <support@altinity.com> |  |

## Values

| Key | Type | Default | Description |
|-----|------|---------|-------------|
| additionalResources | list | `[]` | list of additional resources to create (are processed via `tpl` function) |
| affinity | object | `{}` | affinity for scheduler pod assignment |
| configs | object | `{"confdFiles":null,"configdFiles":{"01-clickhouse-01-listen.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<yandex>\n    <!-- Listen wildcard address to allow accepting connections from other containers and host network. -->\n    <listen_host>::</listen_host>\n    <listen_host>0.0.0.0</listen_host>\n    <listen_try>1</listen_try>\n</yandex>\n","01-clickhouse-02-logger.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<yandex>\n    <logger>\n        <!-- Possible levels: https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/Logger.h#L105 -->\n        <level>debug</level>\n        <log>/var/log/clickhouse-server/clickhouse-server.log</log>\n        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>\n        <size>1000M</size>\n        <count>10</count>\n        <!-- Default behavior is autodetection (log to console if not daemon mode and is tty) -->\n        <console>1</console>\n    </logger>\n</yandex>\n","01-clickhouse-03-query_log.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<yandex>\n    <query_log replace=\"1\">\n        <database>system</database>\n        <table>query_log</table>\n        <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </query_log>\n    <query_thread_log remove=\"1\"/>\n</yandex>\n","01-clickhouse-04-part_log.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<yandex>\n    <part_log replace=\"1\">\n        <database>system</database>\n        <table>part_log</table>\n        <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </part_log>\n</yandex>\n","01-clickhouse-05-trace_log.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<yandex>\n    <trace_log replace=\"1\">\n        <database>system</database>\n        <table>trace_log</table>\n        <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>\n        <flush_interval_milliseconds>7500</flush_interval_milliseconds>\n    </trace_log>\n</yandex>"},"files":{"config.yaml":"# IMPORTANT\n# This file is auto-generated\n# Do not edit this file - all changes would be lost\n# Edit appropriate template in the following folder:\n# deploy/builder/templates-config\n# IMPORTANT\n#\n# Template parameters available:\n#   WATCH_NAMESPACES=\n#   CH_USERNAME_PLAIN=\n#   CH_PASSWORD_PLAIN=\n#   CH_CREDENTIALS_SECRET_NAMESPACE=\n#   CH_CREDENTIALS_SECRET_NAME=clickhouse-operator\n\n################################################\n##\n## Watch section\n##\n################################################\nwatch:\n  # List of namespaces where clickhouse-operator watches for events.\n  # Concurrently running operators should watch on different namespaces.\n  # IMPORTANT\n  # Regexp is applicable.\n  #namespaces: [\"dev\", \"test\"]\n  namespaces: []\n\nclickhouse:\n  configuration:\n    ################################################\n    ##\n    ## Configuration files section\n    ##\n    ################################################\n    file:\n      path:\n        # Path to the folder where ClickHouse configuration files common for all instances within a CHI are located.\n        common: config.d\n        # Path to the folder where ClickHouse configuration files unique for each instance (host) within a CHI are located.\n        host: conf.d\n        # Path to the folder where ClickHouse configuration files with users' settings are located.\n        # Files are common for all instances within a CHI.\n        user: users.d\n    ################################################\n    ##\n    ## Configuration users section\n    ##\n    ################################################\n    user:\n      # Default settings for user accounts, created by the operator.\n      # IMPORTANT. These are not access credentials or settings for 'default' user account,\n      # it is a template for filling out missing fields for all user accounts to be created by the operator,\n      # with the following EXCEPTIONS:\n      # 1. 'default' user account DOES NOT use provided password, but uses all the rest of the fields.\n      #    Password for 'default' user account has to be provided explicitly, if to be used.\n      # 2. CHOP user account DOES NOT use:\n      #    - profile setting. It uses predefined profile called 'clickhouse_operator'\n      #    - quota setting. It uses empty quota name.\n      #    - networks IP setting. Operator specifies 'networks/ip' user setting to match operators' pod IP only.\n      #    - password setting. Password for CHOP account is used from 'clickhouse.access.*' section\n      default:\n        # Default values for ClickHouse user account(s) created by the operator\n        #   1. user/profile - string\n        #   2. user/quota - string\n        #   3. user/networks/ip - multiple strings\n        #   4. user/password - string\n        # These values can be overwritten on per-user basis.\n        profile: \"default\"\n        quota: \"default\"\n        networksIP:\n          - \"::1\"\n          - \"127.0.0.1\"\n        password: \"default\"\n    ################################################\n    ##\n    ## Configuration network section\n    ##\n    ################################################\n    network:\n      # Default host_regexp to limit network connectivity from outside\n      hostRegexpTemplate: \"(chi-{chi}-[^.]+\\\\d+-\\\\d+|clickhouse\\\\-{chi})\\\\.{namespace}\\\\.svc\\\\.cluster\\\\.local$\"\n\n  ################################################\n  ##\n  ## Configuration restart policy section\n  ## Configuration restart policy describes what configuration changes require ClickHouse restart\n  ##\n  ################################################\n  configurationRestartPolicy:\n    rules:\n      # IMPORTANT!\n      # Default version will also be used in case ClickHouse version is unknown.\n      # ClickHouse version may be unknown due to host being down - for example, because of incorrect \"settings\" section.\n      # ClickHouse is not willing to start in case incorrect/unknown settings are provided in config file.\n      - version: \"*\"\n        rules:\n          - settings/*: \"yes\"\n          - settings/dictionaries_config: \"no\"\n          - settings/logger: \"no\"\n          - settings/macros/*: \"no\"\n          - settings/max_server_memory_*: \"no\"\n          - settings/max_*_to_drop: \"no\"\n          - settings/max_concurrent_queries: \"no\"\n          - settings/models_config: \"no\"\n          - settings/user_defined_executable_functions_config: \"no\"\n\n          - zookeeper/*: \"yes\"\n\n          - files/config.d/*.xml: \"yes\"\n          - files/config.d/*dict*.xml: \"no\"\n\n          - profiles/default/background_*_pool_size: \"yes\"\n          - profiles/default/max_*_for_server: \"yes\"\n      - version: \"21.*\"\n        rules:\n          - settings/logger: \"yes\"\n\n  #################################################\n  ##\n  ## Access to ClickHouse instances\n  ##\n  ################################################\n  access:\n    # Possible values for 'scheme' are:\n    #   1. http - force http to be used to connect to ClickHouse instances\n    #   2. https - force https to be used to connect to ClickHouse instances\n    #   3. auto - either http or https is selected based on open ports\n    scheme: \"auto\"\n    # ClickHouse credentials (username, password and port) to be used by the operator to connect to ClickHouse instances.\n    # These credentials are used for:\n    #   1. Metrics requests\n    #   2. Schema maintenance\n    #   3. DROP DNS CACHE\n    # User with these credentials can be specified in additional ClickHouse .xml config files,\n    # located in 'clickhouse.configuration.file.path.user' folder\n    username: \"\"\n    password: \"\"\n    rootCA: \"\"\n\n    # Location of the k8s Secret with username and password to be used by the operator to connect to ClickHouse instances.\n    # Can be used instead of explicitly specified username and password available in sections:\n    #   - clickhouse.access.username\n    #   - clickhouse.access.password\n    # Secret should have two keys:\n    #   1. username\n    #   2. password\n    secret:\n      # Empty `namespace` means that k8s secret would be looked in the same namespace where operator's pod is running.\n      namespace: \"\"\n      # Empty `name` means no k8s Secret would be looked for\n      name: \"{{ include \"altinity-clickhouse-operator.fullname\" . }}\"\n    # Port where to connect to ClickHouse instances to\n    port: 8123\n\n    # Timeouts used to limit connection and queries from the operator to ClickHouse instances\n    # Specified in seconds.\n    timeouts:\n      # Timout to setup connection from the operator to ClickHouse instances. In seconds.\n      connect: 1\n      # Timout to perform SQL query from the operator to ClickHouse instances. In seconds.\n      query: 4\n\n  #################################################\n  ##\n  ## Metrics collection\n  ##\n  ################################################\n\n  metrics:\n    # Timeouts used to limit connection and queries from the metrics exporter to ClickHouse instances\n    # Specified in seconds.\n    timeouts:\n      # Timeout used to limit metrics collection request. In seconds.\n      # Upon reaching this timeout metrics collection is aborted and no more metrics are collected in this cycle.\n      # All collected metrics are returned.\n      collect: 9\n\n################################################\n##\n## Template(s) management section\n##\n################################################\ntemplate:\n  chi:\n    # CHI template updates handling policy\n    # Possible policy values:\n    #   - ReadOnStart. Accept CHIT updates on the operators start only.\n    #   - ApplyOnNextReconcile. Accept CHIT updates at all time. Apply news CHITs on next regular reconcile of the CHI\n    policy: ApplyOnNextReconcile\n\n    # Path to the folder where ClickHouseInstallation templates .yaml manifests are located.\n    # Templates are added to the list of all templates and used when CHI is reconciled.\n    # Templates are applied in sorted alpha-numeric order.\n    path: templates.d\n\n################################################\n##\n## Reconcile section\n##\n################################################\nreconcile:\n  # Reconcile runtime settings\n  runtime:\n    # Max number of concurrent CHI reconciles in progress\n    reconcileCHIsThreadsNumber: 10\n\n    # The operator reconciles shards concurrently in each CHI with the following limitations:\n    #   1. Number of shards being reconciled (and thus having hosts down) in each CHI concurrently\n    #      can not be greater than 'reconcileShardsThreadsNumber'.\n    #   2. Percentage of shards being reconciled (and thus having hosts down) in each CHI concurrently\n    #      can not be greater than 'reconcileShardsMaxConcurrencyPercent'.\n    #   3. The first shard is always reconciled alone. Concurrency starts from the second shard and onward.\n    # Thus limiting number of shards being reconciled (and thus having hosts down) in each CHI by both number and percentage\n\n    # Max number of concurrent shard reconciles within one CHI in progress\n    reconcileShardsThreadsNumber: 5\n    # Max percentage of concurrent shard reconciles within one CHI in progress\n    reconcileShardsMaxConcurrencyPercent: 50\n\n  # Reconcile StatefulSet scenario\n  statefulSet:\n    # Create StatefulSet scenario\n    create:\n      # What to do in case created StatefulSet is not in 'Ready' after `reconcile.statefulSet.update.timeout` seconds\n      # Possible options:\n      # 1. abort - abort the process, do nothing with the problematic StatefulSet, leave it as it is,\n      #    do not try to fix or delete or update it, just abort reconcile cycle.\n      #    Do not proceed to the next StatefulSet(s) and wait for an admin to assist.\n      # 2. delete - delete newly created problematic StatefulSet and follow 'abort' path afterwards.\n      # 3. ignore - ignore an error, pretend nothing happened, continue reconcile and move on to the next StatefulSet.\n      onFailure: ignore\n\n    # Update StatefulSet scenario\n    update:\n      # How many seconds to wait for created/updated StatefulSet to be 'Ready'\n      timeout: 300\n      # How many seconds to wait between checks/polls for created/updated StatefulSet status\n      pollInterval: 5\n      # What to do in case updated StatefulSet is not in 'Ready' after `reconcile.statefulSet.update.timeout` seconds\n      # Possible options:\n      # 1. abort - abort the process, do nothing with the problematic StatefulSet, leave it as it is,\n      #    do not try to fix or delete or update it, just abort reconcile cycle.\n      #    Do not proceed to the next StatefulSet(s) and wait for an admin to assist.\n      # 2. rollback - delete Pod and rollback StatefulSet to previous Generation.\n      #    Pod would be recreated by StatefulSet based on rollback-ed StatefulSet configuration.\n      #    Follow 'abort' path afterwards.\n      # 3. ignore - ignore an error, pretend nothing happened, continue reconcile and move on to the next StatefulSet.\n      onFailure: abort\n\n  # Reconcile Host scenario\n  host:\n    # Whether the operator during reconcile procedure should wait for a ClickHouse host:\n    #   - to be excluded from a ClickHouse cluster\n    #   - to complete all running queries\n    #   - to be included into a ClickHouse cluster\n    # respectfully before moving forward\n    wait:\n      exclude: true\n      queries: true\n      include: false\n\n################################################\n##\n## Annotations management section\n##\n################################################\nannotation:\n  # Applied when:\n  #  1. Propagating annotations from the CHI's `metadata.annotations` to child objects' `metadata.annotations`,\n  #  2. Propagating annotations from the CHI Template's `metadata.annotations` to CHI's `metadata.annotations`,\n  # Include annotations from the following list:\n  # Applied only when not empty. Empty list means \"include all, no selection\"\n  include: []\n  # Exclude annotations from the following list:\n  exclude: []\n\n################################################\n##\n## Labels management section\n##\n################################################\nlabel:\n  # Applied when:\n  #  1. Propagating labels from the CHI's `metadata.labels` to child objects' `metadata.labels`,\n  #  2. Propagating labels from the CHI Template's `metadata.labels` to CHI's `metadata.labels`,\n  # Include labels from the following list:\n  # Applied only when not empty. Empty list means \"include all, no selection\"\n  include: []\n  # Exclude labels from the following list:\n  # Applied only when not empty. Empty list means \"nothing to exclude, no selection\"\n  exclude: []\n  # Whether to append *Scope* labels to StatefulSet and Pod.\n  # Full list of available *scope* labels check in 'labeler.go'\n  #  LabelShardScopeIndex\n  #  LabelReplicaScopeIndex\n  #  LabelCHIScopeIndex\n  #  LabelCHIScopeCycleSize\n  #  LabelCHIScopeCycleIndex\n  #  LabelCHIScopeCycleOffset\n  #  LabelClusterScopeIndex\n  #  LabelClusterScopeCycleSize\n  #  LabelClusterScopeCycleIndex\n  #  LabelClusterScopeCycleOffset\n  appendScope: \"no\"\n\n################################################\n##\n## StatefulSet management section\n##\n################################################\nstatefulSet:\n  revisionHistoryLimit: 0\n\n################################################\n##\n## Pod management section\n##\n################################################\npod:\n  # Grace period for Pod termination.\n  # How many seconds to wait between sending\n  # SIGTERM and SIGKILL during Pod termination process.\n  # Increase this number is case of slow shutdown.\n  terminationGracePeriod: 30\n\n################################################\n##\n## Log parameters section\n##\n################################################\nlogger:\n  logtostderr: \"true\"\n  alsologtostderr: \"false\"\n  v: \"1\"\n  stderrthreshold: \"\"\n  vmodule: \"\"\n  log_backtrace_at: \"\""},"templatesdFiles":{"001-templates.json.example":"{\n  \"apiVersion\": \"clickhouse.altinity.com/v1\",\n  \"kind\": \"ClickHouseInstallationTemplate\",\n  \"metadata\": {\n    \"name\": \"01-default-volumeclaimtemplate\"\n  },\n  \"spec\": {\n    \"templates\": {\n      \"volumeClaimTemplates\": [\n        {\n          \"name\": \"chi-default-volume-claim-template\",\n          \"spec\": {\n            \"accessModes\": [\n              \"ReadWriteOnce\"\n            ],\n            \"resources\": {\n              \"requests\": {\n                \"storage\": \"2Gi\"\n              }\n            }\n          }\n        }\n      ],\n      \"podTemplates\": [\n        {\n          \"name\": \"chi-default-oneperhost-pod-template\",\n          \"distribution\": \"OnePerHost\",\n          \"spec\": {\n            \"containers\" : [\n              {\n                \"name\": \"clickhouse\",\n                \"image\": \"clickhouse/clickhouse-server:22.3\",\n                \"ports\": [\n                  {\n                    \"name\": \"http\",\n                    \"containerPort\": 8123\n                  },\n                  {\n                    \"name\": \"client\",\n                    \"containerPort\": 9000\n                  },\n                  {\n                    \"name\": \"interserver\",\n                    \"containerPort\": 9009\n                  }\n                ]\n              }\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n","default-pod-template.yaml.example":"apiVersion: \"clickhouse.altinity.com/v1\"\nkind: \"ClickHouseInstallationTemplate\"\nmetadata:\n  name: \"default-oneperhost-pod-template\"\nspec:\n  templates:\n    podTemplates:\n      - name: default-oneperhost-pod-template\n        distribution: \"OnePerHost\"\n","default-storage-template.yaml.example":"apiVersion: \"clickhouse.altinity.com/v1\"\nkind: \"ClickHouseInstallationTemplate\"\nmetadata:\n  name: \"default-storage-template-2Gi\"\nspec:\n  templates:\n    volumeClaimTemplates:\n      - name: default-storage-template-2Gi\n        spec:\n          accessModes:\n            - ReadWriteOnce\n          resources:\n            requests:\n              storage: 2Gi\n","readme":"Templates in this folder are packaged with an operator and available via 'useTemplate'"},"usersdFiles":{"01-clickhouse-operator-profile.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<!--\n#\n# Template parameters available:\n#\n-->\n<yandex>\n    <!-- clickhouse-operator user is generated by the operator based on config.yaml in runtime -->\n    <profiles>\n        <clickhouse_operator>\n            <log_queries>0</log_queries>\n            <skip_unavailable_shards>1</skip_unavailable_shards>\n            <http_connection_timeout>10</http_connection_timeout>\n            <max_concurrent_queries_for_all_users>0</max_concurrent_queries_for_all_users>\n            <os_thread_priority>0</os_thread_priority>\n        </clickhouse_operator>\n    </profiles>\n</yandex>\n","02-clickhouse-default-profile.xml":"<!-- IMPORTANT -->\n<!-- This file is auto-generated -->\n<!-- Do not edit this file - all changes would be lost -->\n<!-- Edit appropriate template in the following folder: -->\n<!-- deploy/builder/templates-config -->\n<!-- IMPORTANT -->\n<yandex>\n  <profiles>\n    <default>\n      <os_thread_priority>2</os_thread_priority>\n      <log_queries>1</log_queries>\n      <connect_timeout_with_failover_ms>1000</connect_timeout_with_failover_ms>\n      <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>\n      <parallel_view_processing>1</parallel_view_processing>\n      <do_not_merge_across_partitions_select_final>1</do_not_merge_across_partitions_select_final>\n      <load_balancing>nearest_hostname</load_balancing>\n    </default>\n  </profiles>\n</yandex>"}}` | clickhouse configs |
| dashboards.additionalLabels | object | `{"grafana_dashboard":""}` | labels to add to a secret with dashboards |
| dashboards.annotations | object | `{}` | annotations to add to a secret with dashboards |
| dashboards.enabled | bool | `false` | provision grafana dashboards as secrets (can be synced by grafana dashboards sidecar https://github.com/grafana/helm-charts/blob/grafana-6.33.1/charts/grafana/values.yaml#L679 ) |
| dashboards.grafana_folder | string | `"clickhouse"` |  |
| fullnameOverride | string | `""` | full name of the chart. |
| imagePullSecrets | list | `[]` | image pull secret for private images |
| metrics.containerSecurityContext | object | `{}` |  |
| metrics.enabled | bool | `true` |  |
| metrics.env | list | `[]` | additional environment variables for the deployment |
| metrics.image.pullPolicy | string | `"IfNotPresent"` | image pull policy |
| metrics.image.repository | string | `"altinity/metrics-exporter"` | image repository |
| metrics.image.tag | string | `""` | image tag (chart's appVersion value will be used if not set) |
| metrics.resources | object | `{}` | custom resource configuration |
| nameOverride | string | `""` | override name of the chart |
| nodeSelector | object | `{}` | node for scheduler pod assignment |
| operator.containerSecurityContext | object | `{}` |  |
| operator.env | list | `[]` | additional environment variables for the deployment |
| operator.image.pullPolicy | string | `"IfNotPresent"` | image pull policy |
| operator.image.repository | string | `"altinity/clickhouse-operator"` | image repository |
| operator.image.tag | string | `""` | image tag (chart's appVersion value will be used if not set) |
| operator.resources | object | `{}` | custom resource configuration |
| podAnnotations | object | `{"prometheus.io/port":"8888","prometheus.io/scrape":"true"}` | annotations to add to the pod |
| podSecurityContext | object | `{}` |  |
| secret.create | bool | `true` | create a secret with operator credentials |
| secret.password | string | `"clickhouse_operator_password"` | operator credentials password |
| secret.username | string | `"clickhouse_operator"` | operator credentials username |
| serviceAccount.annotations | object | `{}` | annotations to add to the service account |
| serviceAccount.create | bool | `true` | specifies whether a service account should be created |
| serviceAccount.name | string | `nil` | the name of the service account to use; if not set and create is true, a name is generated using the fullname template |
| serviceMonitor.additionalLabels | object | `{}` | additional labels for service monitor |
| serviceMonitor.enabled | bool | `false` | ServiceMonitor CRD is created for a prometheus operator |
| tolerations | list | `[]` | tolerations for scheduler pod assignment |

