#
# Template parameters available:
#   WATCH_NAMESPACES=${WATCH_NAMESPACES}
#   CH_USERNAME_PLAIN=${CH_USERNAME_PLAIN}
#   CH_PASSWORD_PLAIN=${CH_PASSWORD_PLAIN}
#   CH_CREDENTIALS_SECRET_NAMESPACE=${CH_CREDENTIALS_SECRET_NAMESPACE}
#   CH_CREDENTIALS_SECRET_NAME=${CH_CREDENTIALS_SECRET_NAME}
#   VERBOSITY=${VERBOSITY}

################################################
##
## Watch section
##
################################################
watch:
  # List of namespaces where clickhouse-operator watches for events.
  # Concurrently running operators should watch on different namespaces.
  # IMPORTANT
  # Regexp is applicable.
  namespaces: [${WATCH_NAMESPACES}]

clickhouse:
  configuration:
    ################################################
    ##
    ## Configuration files section
    ##
    ################################################
    file:
      # Each 'path' can be either absolute or relative.
      # In case path is absolute - it is used as is
      # In case path is relative - it is relative to the folder where configuration file you are reading right now is located.
      path:
        # Path to the folder where ClickHouse configuration files common for all instances within a CHI are located.
        common: chi/config.d
        # Path to the folder where ClickHouse configuration files unique for each instance (host) within a CHI are located.
        host: chi/conf.d
        # Path to the folder where ClickHouse configuration files with users' settings are located.
        # Files are common for all instances within a CHI.
        user: chi/users.d
    ################################################
    ##
    ## Configuration users section
    ##
    ################################################
    user:
      # Default settings for user accounts, created by the operator.
      # IMPORTANT. These are not access credentials or settings for 'default' user account,
      # it is a template for filling out missing fields for all user accounts to be created by the operator,
      # with the following EXCEPTIONS:
      # 1. 'default' user account DOES NOT use provided password, but uses all the rest of the fields.
      #    Password for 'default' user account has to be provided explicitly, if to be used.
      # 2. CHOP user account DOES NOT use:
      #    - profile setting. It uses predefined profile called 'clickhouse_operator'
      #    - quota setting. It uses empty quota name.
      #    - networks IP setting. Operator specifies 'networks/ip' user setting to match operators' pod IP only.
      #    - password setting. Password for CHOP account is used from 'clickhouse.access.*' section
      default:
        # Default values for ClickHouse user account(s) created by the operator
        #   1. user/profile - string
        #   2. user/quota - string
        #   3. user/networks/ip - multiple strings
        #   4. user/password - string
        # These values can be overwritten on per-user basis.
        profile: "default"
        quota: "default"
        networksIP:
          - "::1"
          - "127.0.0.1"
        password: "default"
    ################################################
    ##
    ## Configuration network section
    ##
    ################################################
    network:
      # Default host_regexp to limit network connectivity from outside
      hostRegexpTemplate: "(chi-{chi}-[^.]+\\d+-\\d+|clickhouse\\-{chi})\\.{namespace}\\.svc\\.cluster\\.local$"

  ################################################
  ##
  ## Configuration restart policy section
  ## Configuration restart policy describes what configuration changes require ClickHouse restart
  ##
  ################################################
  configurationRestartPolicy:
    rules:
      # IMPORTANT!
      # Special version of "*" - default version - has to satisfy all ClickHouse versions.
      # Default version will also be used in case ClickHouse version is unknown.
      # ClickHouse version may be unknown due to host being down - for example, because of incorrect "settings" section.
      # ClickHouse is not willing to start in case incorrect/unknown settings are provided in config file.
      - version: "*"
        rules:
          # see https://kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-server-config-files/#server-config-configxml-sections-which-dont-require-restart
          # to be replaced with "select * from system.server_settings where changeable_without_restart = 'No'"

          - settings/*: "yes"

          # single values
          - settings/access_control_path: "no"
          - settings/dictionaries_config: "no"
          - settings/max_server_memory_*: "no"
          - settings/max_*_to_drop: "no"
          - settings/max_concurrent_queries: "no"
          - settings/models_config: "no"
          - settings/user_defined_executable_functions_config: "no"

          # structured XML
          - settings/logger/*: "no"
          - settings/macros/*: "no"
          - settings/remote_servers/*: "no"
          - settings/user_directories/*: "no"

          # these settings should not lead to pod restarts
          - settings/display_secrets_in_show_and_select: "no"

          - zookeeper/*: "no"

          - files/*.xml: "yes"
          - files/config.d/*.xml: "yes"
          - files/config.d/*dict*.xml: "no"
          - files/config.d/*no_restart*: "no"

          # exceptions in default profile
          - profiles/default/background_*_pool_size: "yes"
          - profiles/default/max_*_for_server: "yes"
      - version: "21.*"
        rules:
          - settings/logger: "yes"

  #################################################
  ##
  ## Access to ClickHouse instances
  ##
  ################################################
  access:
    # Possible values for 'scheme' are:
    #   1. http - force http to be used to connect to ClickHouse instances
    #   2. https - force https to be used to connect to ClickHouse instances
    #   3. auto - either http or https is selected based on open ports
    scheme: "auto"
    # ClickHouse credentials (username, password and port) to be used by the operator to connect to ClickHouse instances.
    # These credentials are used for:
    #   1. Metrics requests
    #   2. Schema maintenance
    # User with these credentials can be specified in additional ClickHouse .xml config files,
    # located in 'clickhouse.configuration.file.path.user' folder
    username: "${CH_USERNAME_PLAIN}"
    password: "${CH_PASSWORD_PLAIN}"
    rootCA: ""

    # Location of the k8s Secret with username and password to be used by the operator to connect to ClickHouse instances.
    # Can be used instead of explicitly specified username and password available in sections:
    #   - clickhouse.access.username
    #   - clickhouse.access.password
    # Secret should have two keys:
    #   1. username
    #   2. password
    secret:
      # Empty `namespace` means that k8s secret would be looked in the same namespace where operator's pod is running.
      namespace: "${CH_CREDENTIALS_SECRET_NAMESPACE}"
      # Empty `name` means no k8s Secret would be looked for
      name: "${CH_CREDENTIALS_SECRET_NAME}"
    # Port where to connect to ClickHouse instances to
    port: 8123

    # Timeouts used to limit connection and queries from the operator to ClickHouse instances
    # Specified in seconds.
    timeouts:
      # Timout to setup connection from the operator to ClickHouse instances. In seconds.
      connect: 1
      # Timout to perform SQL query from the operator to ClickHouse instances. In seconds.
      query: 4

  ################################################
  ##
  ## Addons specifies additional configuration sections
  ## Should it be called something like "templates"?
  ##
  ################################################
  addons:
    rules:
      - version: "*"
        spec:
          configuration:
            users:
            profiles:
            quotas:
            settings:
            files:
      - version: ">= 23.3"
        spec:
          configuration:
            ###
            ### users.d is global while description depends on CH version which may vary on per-host basis
            ### In case of global-ness this may be better to implement via auto-templates
            ###
            ### As a solution, this may be applied on the whole cluster based on any of its hosts
            ###
            ### What to do when host is just created? CH version is not known prior to CH started and user config is required before CH started.
            ### We do not have any info about the cluster on initial creation
            ###
            users:
              "{clickhouseOperatorUser}/access_management": 1
              "{clickhouseOperatorUser}/named_collection_control": 1
              "{clickhouseOperatorUser}/show_named_collections": 1
              "{clickhouseOperatorUser}/show_named_collections_secrets": 1
            profiles:
            quotas:
            settings:
            files:

      - version: ">= 23.5"
        spec:
          configuration:
            users:
            profiles:
              clickhouse_operator/format_display_secrets_in_show_and_select: 1
            quotas:
            settings:
              ##
              ## this may be added on per-host basis into host's conf.d folder
              ##
              display_secrets_in_show_and_select: 1
            files:

  #################################################
  ##
  ## Metrics collection
  ##
  ################################################

  metrics:
    # Timeouts used to limit connection and queries from the metrics exporter to ClickHouse instances
    # Specified in seconds.
    timeouts:
      # Timeout used to limit metrics collection request. In seconds.
      # Upon reaching this timeout metrics collection is aborted and no more metrics are collected in this cycle.
      # All collected metrics are returned.
      collect: 9

keeper:
  configuration:
    ################################################
    ##
    ## Configuration files section
    ##
    ################################################
    file:
      # Each 'path' can be either absolute or relative.
      # In case path is absolute - it is used as is
      # In case path is relative - it is relative to the folder where configuration file you are reading right now is located.
      path:
        # Path to the folder where Keeper configuration files common for all instances within a CHK are located.
        common: chk/keeper_config.d
        # Path to the folder where Keeper configuration files unique for each instance (host) within a CHK are located.
        host: chk/conf.d
        # Path to the folder where Keeper configuration files with users' settings are located.
        # Files are common for all instances within a CHI.
        user: chk/users.d

################################################
##
## Template(s) management section
##
################################################
template:
  chi:
    # CHI template updates handling policy
    # Possible policy values:
    #   - ReadOnStart. Accept CHIT updates on the operator's start only.
    #   - ApplyOnNextReconcile. Accept CHIT updates at all time. Apply new CHITs on next regular reconcile of the CHI
    policy: ApplyOnNextReconcile

    # Path to the folder where ClickHouseInstallation templates .yaml manifests are located.
    # Templates are added to the list of all templates and used when CHI is reconciled.
    # Templates are applied in sorted alpha-numeric order.
    path: chi/templates.d
  chk:
    # CHK template updates handling policy
    # Possible policy values:
    #   - ReadOnStart. Accept CHIT updates on the operators start only.
    #   - ApplyOnNextReconcile. Accept CHIT updates at all time. Apply new CHITs on next regular reconcile of the CHI
    policy: ApplyOnNextReconcile

    # Path to the folder where ClickHouseInstallation templates .yaml manifests are located.
    # Templates are added to the list of all templates and used when CHI is reconciled.
    # Templates are applied in sorted alpha-numeric order.
    path: chk/templates.d

################################################
##
## Reconcile section
##
################################################
reconcile:
  # Reconcile runtime settings
  runtime:
    # Max number of concurrent CHI reconciles in progress
    reconcileCHIsThreadsNumber: 10

    # The operator reconciles shards concurrently in each CHI with the following limitations:
    #   1. Number of shards being reconciled (and thus having hosts down) in each CHI concurrently
    #      can not be greater than 'reconcileShardsThreadsNumber'.
    #   2. Percentage of shards being reconciled (and thus having hosts down) in each CHI concurrently
    #      can not be greater than 'reconcileShardsMaxConcurrencyPercent'.
    #   3. The first shard is always reconciled alone. Concurrency starts from the second shard and onward.
    # Thus limiting number of shards being reconciled (and thus having hosts down) in each CHI by both number and percentage

    # Max number of concurrent shard reconciles within one cluster in progress
    reconcileShardsThreadsNumber: 5
    # Max percentage of concurrent shard reconciles within one cluster in progress
    reconcileShardsMaxConcurrencyPercent: 50

  # Reconcile StatefulSet scenario
  statefulSet:
    # Create StatefulSet scenario
    create:
      # What to do in case created StatefulSet is not in 'Ready' after `reconcile.statefulSet.update.timeout` seconds
      # Possible options:
      # 1. abort - abort the process, do nothing with the problematic StatefulSet, leave it as it is,
      #    do not try to fix or delete or update it, just abort reconcile cycle.
      #    Do not proceed to the next StatefulSet(s) and wait for an admin to assist.
      # 2. delete - delete newly created problematic StatefulSet and follow 'abort' path afterwards.
      # 3. ignore - ignore an error, pretend nothing happened, continue reconcile and move on to the next StatefulSet.
      onFailure: ignore

    # Update StatefulSet scenario
    update:
      # How many seconds to wait for created/updated StatefulSet to be 'Ready'
      timeout: 300
      # How many seconds to wait between checks/polls for created/updated StatefulSet status
      pollInterval: 5
      # What to do in case updated StatefulSet is not in 'Ready' after `reconcile.statefulSet.update.timeout` seconds
      # Possible options:
      # 1. abort - abort the process, do nothing with the problematic StatefulSet, leave it as it is,
      #    do not try to fix or delete or update it, just abort reconcile cycle.
      #    Do not proceed to the next StatefulSet(s) and wait for an admin to assist.
      # 2. rollback - delete Pod and rollback StatefulSet to previous Generation.
      #    Pod would be recreated by StatefulSet based on rollback-ed StatefulSet configuration.
      #    Follow 'abort' path afterwards.
      # 3. ignore - ignore an error, pretend nothing happened, continue reconcile and move on to the next StatefulSet.
      onFailure: abort

  # Reconcile Host scenario
  host:
    # The operator during reconcile procedure should wait for a ClickHouse host to achieve the following conditions:
    wait:
      # Whether the operator during reconcile procedure should wait for a ClickHouse host:
      #   - to be excluded from a ClickHouse cluster
      #   - to complete all running queries
      #   - to be included into a ClickHouse cluster
      # respectfully before moving forward with host reconcile
      exclude: true
      queries: true
      include: false
      # The operator during reconcile procedure should wait for replicas to catch-up
      # replication delay a.k.a replication lag for the following replicas
      replicas:
        # All replicas (new and known earlier) are explicitly requested to wait for replication to catch-up
        all: no
        # New replicas only are requested to wait for replication to catch-up
        new: yes
        # Replication catch-up is considered to be completed as soon as replication delay
        # a.k.a replication lag - calculated as "MAX(absolute_delay) FROM system.replicas"
        # is within this specified delay (in seconds)
        delay: 10
      probes:
        # Whether the operator during host launch procedure should wait for startup probe to succeed.
        # In case probe is unspecified wait is assumed to be completed successfully.
        # Default option value is to do not wait.
        startup: no
        # Whether the operator during host launch procedure should wait for readiness probe to succeed.
        # In case probe is unspecified wait is assumed to be completed successfully.
        # Default option value is to wait.
        readiness: yes
    # The operator during reconcile procedure should drop the following entities:
    drop:
      replicas:
        # Whether the operator during reconcile procedure should drop replicas when replica is deleted
        onDelete: yes
        # Whether the operator during reconcile procedure should drop replicas when replica volume is lost
        onLostVolume: yes
        # Whether the operator during reconcile procedure should drop active replicas when replica is deleted or recreated
        active: no

################################################
##
## Annotations management section
##
################################################
annotation:
  # Applied when:
  #  1. Propagating annotations from the CHI's `metadata.annotations` to child objects' `metadata.annotations`,
  #  2. Propagating annotations from the CHI Template's `metadata.annotations` to CHI's `metadata.annotations`,
  # Include annotations from the following list:
  # Applied only when not empty. Empty list means "include all, no selection"
  include: []
  # Exclude annotations from the following list:
  exclude: []

################################################
##
## Labels management section
##
################################################
label:
  # Applied when:
  #  1. Propagating labels from the CHI's `metadata.labels` to child objects' `metadata.labels`,
  #  2. Propagating labels from the CHI Template's `metadata.labels` to CHI's `metadata.labels`,
  # Include labels from the following list:
  # Applied only when not empty. Empty list means "include all, no selection"
  include: []
  # Exclude labels from the following list:
  # Applied only when not empty. Empty list means "nothing to exclude, no selection"
  exclude: []
  # Whether to append *Scope* labels to StatefulSet and Pod.
  # Full list of available *scope* labels check in 'labeler.go'
  #  LabelShardScopeIndex
  #  LabelReplicaScopeIndex
  #  LabelCHIScopeIndex
  #  LabelCHIScopeCycleSize
  #  LabelCHIScopeCycleIndex
  #  LabelCHIScopeCycleOffset
  #  LabelClusterScopeIndex
  #  LabelClusterScopeCycleSize
  #  LabelClusterScopeCycleIndex
  #  LabelClusterScopeCycleOffset
  appendScope: "no"

################################################
##
## Metrics management section
##
################################################
metrics:
  labels:
    exclude: []

################################################
##
## Status management section
##
################################################
status:
  fields:
    action: false
    actions: false
    error: false
    errors: false

################################################
##
## StatefulSet management section
##
################################################
statefulSet:
  revisionHistoryLimit: 0

################################################
##
## Pod management section
##
################################################
pod:
  # Grace period for Pod termination.
  # How many seconds to wait between sending
  # SIGTERM and SIGKILL during Pod termination process.
  # Increase this number is case of slow shutdown.
  terminationGracePeriod: 30

################################################
##
## Log parameters section
##
################################################
logger:
  logtostderr: "true"
  alsologtostderr: "false"
  v: "${VERBOSITY}"
  stderrthreshold: ""
  vmodule: ""
  log_backtrace_at: ""
